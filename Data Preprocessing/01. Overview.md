# Overview
> Data preprocessing is an important step in the data mining process. The phrase "garbage in, garbage out" is particularly applicable to data mining and machine learning projects.

**Why is data preprocessing required?**
- Data can be:
  1. Incomplete
  2. Inconsistent
  3. Inaccurate (with errors or outliers)
  4. Can lack specific attributes, values or trends

**What is feature engineering?**
- Creating new features from existing features
- Use domain knowledge
- Can be used to improve the performance of models

### Common Preprocessing Steps
- Missing Values
- Vectorization
- Feature Scaling, etc

**To deal with missing values:**
- Delete the row
- Imputate (Apply mean, median or kNN)

**Vectorization**
- Encoding categorical data
  - As integers (For eg, consider the deck of cards, you can number all 4 shapes from 1 - 4)
  - As a dummy variable (One - hot encoding) (For eg, take the same example and give each shape a variable name which takes binary values)

**Feature Scaling**
- Normalization: Scaling data between 0 and 1
- Standardization: Transforming data between 0(mean) and 1(standard deviation)

**Other preprocessing steps**
- Downsampling or Upsampling, i.e., if the data is imbalanced, make number of occureneces equal, if there is a rare case it is called as **other**

### Packages used:
- recipes
- rsample

### Resources:
- https://recipes.tidymodels.org
- https://rsample.tidymodels.org